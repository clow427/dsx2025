{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf4ac71-1361-4285-b0db-74618a8e26ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant columns: ['Name', 'Naics Code Description', 'NAICS Code', 'Address', 'City', 'County', 'State', 'Zip Code', 'Excess Food Estimate, Low (tons per year)', 'Excess Food Estimate, High (tons per year)', 'UniqueID', 'Longitude', 'Latitude', 'AvgExcessFoodWaste']\n",
      "\n",
      "First few rows of coordinates:\n",
      "   Longitude   Latitude\n",
      "0 -71.112600  42.369921\n",
      "1 -71.014286  42.278453\n",
      "2 -70.932417  42.079941\n",
      "3 -71.449229  42.565285\n",
      "4 -71.058747  42.359146\n",
      "\n",
      ":white_check_mark: Loaded 7757 restaurants with valid coordinates\n",
      ":white_check_mark: Matched 7757 restaurants to census tracts\n",
      ":white_check_mark: Created top 3 restaurants for 1460 census tracts\n",
      ":white_check_mark: Computed improved NeedScore using nonlinear normalization\n",
      ":white_check_mark: Saved GeoPackage with geometries preserved\n",
      ":white_check_mark: Saved CSV with centroid coordinates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/9y9b_5vd6z19v61y8f2qsgb40000gn/T/ipykernel_40585/4048820155.py:172: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  tracts_summary_csv[\"Centroid_Lat\"] = tracts_summary_csv.geometry.centroid.y\n",
      "/var/folders/3c/9y9b_5vd6z19v61y8f2qsgb40000gn/T/ipykernel_40585/4048820155.py:173: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  tracts_summary_csv[\"Centroid_Lon\"] = tracts_summary_csv.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORTS\n",
    "# ============================================================\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "# ============================================================\n",
    "# STEP 1: Load Food Access data\n",
    "# ============================================================\n",
    "df_food = pd.read_csv(\"FoodAccessResearchAtlasData2019.csv\")\n",
    "# Ensure CensusTract is string and zero-padded\n",
    "df_food[\"CensusTract\"] = df_food[\"CensusTract\"].astype(str).str.zfill(11)\n",
    "# Keep only needed columns\n",
    "df_food = df_food[[\"CensusTract\", \"MedianFamilyIncome\", \"PovertyRate\", \"LAPOP1_10\"]]\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Load Massachusetts census tracts shapefile\n",
    "# ============================================================\n",
    "fips = \"25\"  # Massachusetts\n",
    "tracts = gpd.read_file(f\"https://www2.census.gov/geo/tiger/TIGER2020/TRACT/tl_2020_{fips}_tract.zip\")\n",
    "# Fix: Explicitly set and then re-project the CRS for tracts\n",
    "tracts = tracts.set_crs(\"EPSG:4269\", allow_override=True).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Load restaurant data\n",
    "# ============================================================\n",
    "restaurants = pd.read_csv(\"filtered_restaurants_and_food(final).csv\")\n",
    "restaurants.columns = restaurants.columns.str.strip()\n",
    "# Detect county column automatically\n",
    "county_col = next((c for c in restaurants.columns if \"county\" in c.lower()), None)\n",
    "# Debug: Check coordinate columns\n",
    "print(\"Restaurant columns:\", restaurants.columns.tolist())\n",
    "print(\"\\nFirst few rows of coordinates:\")\n",
    "print(restaurants[[\"Longitude\", \"Latitude\"]].head())\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Convert restaurants to GeoDataFrame and assign tracts\n",
    "# ============================================================\n",
    "# Make sure coordinates are numeric and not null\n",
    "restaurants = restaurants.dropna(subset=[\"Longitude\", \"Latitude\"])\n",
    "restaurants[\"Longitude\"] = pd.to_numeric(restaurants[\"Longitude\"], errors='coerce')\n",
    "restaurants[\"Latitude\"] = pd.to_numeric(restaurants[\"Latitude\"], errors='coerce')\n",
    "restaurants = restaurants.dropna(subset=[\"Longitude\", \"Latitude\"])\n",
    "print(f\"\\n:white_check_mark: Loaded {len(restaurants)} restaurants with valid coordinates\")\n",
    "# Create GeoDataFrame - Longitude is X, Latitude is Y\n",
    "restaurants_gdf = gpd.GeoDataFrame(\n",
    "    restaurants,\n",
    "    geometry=gpd.points_from_xy(restaurants[\"Longitude\"], restaurants[\"Latitude\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "# Spatial join - this assigns each restaurant to its containing tract\n",
    "restaurants_with_tract = gpd.sjoin(\n",
    "    restaurants_gdf,\n",
    "    tracts[[\"GEOID\", \"geometry\"]],\n",
    "    how=\"inner\",  # Only keep restaurants that fall within a tract\n",
    "    predicate=\"within\"\n",
    ")\n",
    "restaurants_with_tract[\"CensusTract\"] = restaurants_with_tract[\"GEOID\"]\n",
    "print(f\":white_check_mark: Matched {len(restaurants_with_tract)} restaurants to census tracts\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Compute top 3 surplus restaurants per tract\n",
    "# ============================================================\n",
    "cols_needed = [\n",
    "    \"CensusTract\",\n",
    "    \"UniqueID\",\n",
    "    \"Name\",\n",
    "    \"Address\",\n",
    "    \"AvgExcessFoodWaste\"\n",
    "]\n",
    "if county_col:\n",
    "    cols_needed.insert(4, county_col)\n",
    "# Filter to restaurants WITH a CensusTract assignment\n",
    "restaurants_with_tract = restaurants_with_tract[cols_needed].dropna(subset=[\"CensusTract\", \"AvgExcessFoodWaste\"])\n",
    "# Sort by CensusTract and AvgExcessFoodWaste\n",
    "restaurants_sorted = restaurants_with_tract.sort_values(\n",
    "    [\"CensusTract\", \"AvgExcessFoodWaste\"],\n",
    "    ascending=[True, False]\n",
    ")\n",
    "# Rank WITHIN each tract group\n",
    "restaurants_sorted[\"Rank\"] = restaurants_sorted.groupby(\"CensusTract\")[\"AvgExcessFoodWaste\"].rank(\n",
    "    method=\"first\",\n",
    "    ascending=False\n",
    ")\n",
    "# Keep only top 3 per tract\n",
    "top3 = restaurants_sorted[restaurants_sorted[\"Rank\"] <= 3].copy()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5B: Pivot top 3 restaurants to wide format\n",
    "# ============================================================\n",
    "top3_pivot = top3.pivot_table(\n",
    "    index=\"CensusTract\",\n",
    "    columns=\"Rank\",\n",
    "    values=[\"Name\", \"Address\", \"AvgExcessFoodWaste\"],\n",
    "    aggfunc=\"first\"\n",
    ")\n",
    "# Flatten column names\n",
    "top3_pivot.columns = [f\"{col[0]}_Top{int(col[1])}\" for col in top3_pivot.columns]\n",
    "top3_pivot = top3_pivot.reset_index()\n",
    "print(f\":white_check_mark: Created top 3 restaurants for {len(top3_pivot)} census tracts\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: Merge with food access data and tracts\n",
    "# ============================================================\n",
    "tracts_summary = tracts.merge(df_food, left_on=\"GEOID\", right_on=\"CensusTract\", how=\"left\")\n",
    "tracts_summary = tracts_summary.merge(top3_pivot, on=\"CensusTract\", how=\"left\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7: Compute NeedScore (Improved Normalization)\n",
    "# ============================================================\n",
    "# ---------- Helper functions ----------\n",
    "def scale_0_1(series):\n",
    "    \"\"\"Min–max scale to [0, 1] range, handling NaNs.\"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min())\n",
    "def nonlinear_scale(series, alpha=2):\n",
    "    \"\"\"\n",
    "    Apply exponential scaling to emphasize higher-need tracts.\n",
    "    alpha > 0 increases contrast (e.g., alpha=2 or 3).\n",
    "    \"\"\"\n",
    "    norm = scale_0_1(series.fillna(series.min()))\n",
    "    return (np.exp(alpha * norm) - 1) / (np.exp(alpha) - 1)\n",
    "# ---------- Normalize individual indicators ----------\n",
    "# PovertyRate: higher → more need\n",
    "tracts_summary[\"norm_poverty\"] = nonlinear_scale(tracts_summary[\"PovertyRate\"], alpha=2)\n",
    "# LAPOP1_10: higher → more need (more low-access population)\n",
    "tracts_summary[\"norm_lapop\"] = nonlinear_scale(tracts_summary[\"LAPOP1_10\"], alpha=2)\n",
    "# MedianFamilyIncome: higher → less need (invert)\n",
    "income_norm = scale_0_1(tracts_summary[\"MedianFamilyIncome\"])\n",
    "tracts_summary[\"norm_income_need\"] = nonlinear_scale(1 - income_norm, alpha=2)\n",
    "# ---------- Combine into final NeedScore ----------\n",
    "tracts_summary[\"NeedScore\"] = (\n",
    "    0.5 * tracts_summary[\"norm_poverty\"] +\n",
    "    0.3 * tracts_summary[\"norm_lapop\"] +\n",
    "    0.2 * tracts_summary[\"norm_income_need\"]\n",
    ")\n",
    "# Optional: Normalize NeedScore again to [0,1] for easier interpretation\n",
    "tracts_summary[\"NeedScore\"] = scale_0_1(tracts_summary[\"NeedScore\"])\n",
    "print(\":white_check_mark: Computed improved NeedScore using nonlinear normalization\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 8: Rename columns for output consistency\n",
    "# ============================================================\n",
    "rename_map = {\n",
    "    \"Name_Top1\": \"FoodProvider_1\",\n",
    "    \"Name_Top2\": \"FoodProvider_2\",\n",
    "    \"Name_Top3\": \"FoodProvider_3\",\n",
    "    \"AvgExcessFoodWaste_Top1\": \"AvgSurplus_Provider1\",\n",
    "    \"AvgExcessFoodWaste_Top2\": \"AvgSurplus_Provider2\",\n",
    "    \"AvgExcessFoodWaste_Top3\": \"AvgSurplus_Provider3\",\n",
    "    \"Address_Top1\": \"Address_Provider1\",\n",
    "    \"Address_Top2\": \"Address_Provider2\",\n",
    "    \"Address_Top3\": \"Address_Provider3\"\n",
    "}\n",
    "tracts_summary = tracts_summary.rename(columns=rename_map)\n",
    "# Define final columns (added PovertyRate)\n",
    "columns_to_keep = [\n",
    "    \"CensusTract\",\n",
    "    \"FoodProvider_1\", \"FoodProvider_2\", \"FoodProvider_3\",\n",
    "    \"AvgSurplus_Provider1\", \"AvgSurplus_Provider2\", \"AvgSurplus_Provider3\",\n",
    "    \"Address_Provider1\", \"Address_Provider2\", \"Address_Provider3\",\n",
    "    \"MedianFamilyIncome\",\n",
    "    \"PovertyRate\",\n",
    "    \"NeedScore\",\n",
    "    \"geometry\"\n",
    "]\n",
    "# Keep only existing columns (avoid KeyErrors)\n",
    "tracts_summary = tracts_summary[[c for c in columns_to_keep if c in tracts_summary.columns]]\n",
    "# Drop rows where CensusTract is missing\n",
    "tracts_summary = tracts_summary.dropna(subset=[\"CensusTract\"])\n",
    "\n",
    "# ============================================================\n",
    "# STEP 9: Save GeoPackage for ArcGIS\n",
    "# ============================================================\n",
    "tracts_summary.to_file(\"tract_summary_top3_restaurants.gpkg\", layer=\"tracts_summary\", driver=\"GPKG\")\n",
    "print(\":white_check_mark: Saved GeoPackage with geometries preserved\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 10: Save CSV with centroid coordinates\n",
    "# ============================================================\n",
    "tracts_summary_csv = tracts_summary.copy()\n",
    "tracts_summary_csv[\"Centroid_Lat\"] = tracts_summary_csv.geometry.centroid.y\n",
    "tracts_summary_csv[\"Centroid_Lon\"] = tracts_summary_csv.geometry.centroid.x\n",
    "tracts_summary_csv = tracts_summary_csv.drop(columns=[\"geometry\"])\n",
    "tracts_summary_csv.to_csv(\"tract_summary_top3_restaurants.csv\", index=False)\n",
    "print(\":white_check_mark: Saved CSV with centroid coordinates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
